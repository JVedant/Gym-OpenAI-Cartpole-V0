{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary librarise\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from tensorflow.keras import Sequential\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.activations import relu, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Class for Deep Q learning\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    # initialize using the action and state size\n",
    "    def __init__(self, action_space, state_space):\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.epsilon = 1.0\n",
    "        self.gamma = .99\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = .01\n",
    "        self.lr = 0.001\n",
    "        self.epsilon_decay = .996\n",
    "        self.memory = deque(maxlen=1000000)\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # building and compiling a neural network of n (here n=3) layers \n",
    "    def build_model(self):\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(150, input_dim=self.state_space, activation=relu),\n",
    "            Dense(120, activation=relu),\n",
    "            Dense(self.action_space, activation=linear)])\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.lr))\n",
    "        return model\n",
    "    \n",
    "    #saving a model\n",
    "    def save_model(self):\n",
    "        self.model.save('Cartpole-model')\n",
    "\n",
    "    # creating checkpoints (adding in memory)\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # predicting the next action from current state\n",
    "    def act(self, state):\n",
    "\n",
    "        # checking for exploration or exploitation\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "    def replay(self):\n",
    "\n",
    "        # if batchsize is greater is less than memory size then exit\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        \n",
    "        # fetching data from minibatch and assigning to states, actions, rewards, next_states and dones\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = np.array([i[0] for i in minibatch])\n",
    "        actions = np.array([i[1] for i in minibatch])\n",
    "        rewards = np.array([i[2] for i in minibatch])\n",
    "        next_states = np.array([i[3] for i in minibatch])\n",
    "        dones = np.array([i[4] for i in minibatch])\n",
    "\n",
    "        # Remove single-dimensional entries from states and next_states.\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "        \n",
    "        # setting target values\n",
    "        targets = rewards + self.gamma*(np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones)\n",
    "        targets_full = self.model.predict_on_batch(states)\n",
    "        ind = np.array([i for i in range(self.batch_size)])\n",
    "        targets_full[[ind], [actions]] = targets\n",
    "\n",
    "        # training the model\n",
    "        self.model.fit(states, targets_full, epochs=1, verbose=0)\n",
    "        \n",
    "        # reducing the epsilon to reduce exploitation\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Deep q-learning network\n",
    "\n",
    "def train_dqn(episode):\n",
    "\n",
    "    loss = []\n",
    "    \n",
    "    # getting the agent from DQN class (environment)\n",
    "    agent = DQN(env.action_space.n, env.observation_space.shape[0])\n",
    "    \n",
    "    #iterate for each episode\n",
    "    for e in range(episode):\n",
    "        \n",
    "        # getting a state by reseting the environment\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, (1, 4))\n",
    "        score = 0\n",
    "        max_steps = 3000\n",
    "        \n",
    "        #for all states in each episode\n",
    "        for i in range(max_steps):\n",
    "            # getting the action from environment at a particular state\n",
    "            action = agent.act(state)\n",
    "            env.render()\n",
    "            \n",
    "            # calculating the reward and next state for a selected action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            next_state = np.reshape(next_state, (1, 4))\n",
    "            \n",
    "            # adding the agents learning to memory\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            agent.replay()\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, episode, score))\n",
    "                break\n",
    "        loss.append(score)\n",
    "\n",
    "        # Average score of last 100 episode\n",
    "        is_solved = np.mean(loss[-100:])\n",
    "        if is_solved > 50:\n",
    "            print('\\n Task Completed! \\n')\n",
    "            agent.save_model()\n",
    "            break\n",
    "        print(\"Average over last 100 episode: {0:.2f} \\n\".format(is_solved))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an environment of Cartpole-v0\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\n",
      "Discrete(2)\n",
      "episode: 0/400, score: 16.0\n",
      "Average over last 100 episode: 16.00 \n",
      "\n",
      "episode: 1/400, score: 15.0\n",
      "Average over last 100 episode: 15.50 \n",
      "\n",
      "episode: 2/400, score: 15.0\n",
      "Average over last 100 episode: 15.33 \n",
      "\n",
      "episode: 3/400, score: 19.0\n",
      "Average over last 100 episode: 16.25 \n",
      "\n",
      "episode: 4/400, score: 15.0\n",
      "Average over last 100 episode: 16.00 \n",
      "\n",
      "episode: 5/400, score: 17.0\n",
      "Average over last 100 episode: 16.17 \n",
      "\n",
      "episode: 6/400, score: 10.0\n",
      "Average over last 100 episode: 15.29 \n",
      "\n",
      "episode: 7/400, score: 14.0\n",
      "Average over last 100 episode: 15.12 \n",
      "\n",
      "episode: 8/400, score: 20.0\n",
      "Average over last 100 episode: 15.67 \n",
      "\n",
      "episode: 9/400, score: 21.0\n",
      "Average over last 100 episode: 16.20 \n",
      "\n",
      "episode: 10/400, score: 8.0\n",
      "Average over last 100 episode: 15.45 \n",
      "\n",
      "episode: 11/400, score: 27.0\n",
      "Average over last 100 episode: 16.42 \n",
      "\n",
      "episode: 12/400, score: 14.0\n",
      "Average over last 100 episode: 16.23 \n",
      "\n",
      "episode: 13/400, score: 10.0\n",
      "Average over last 100 episode: 15.79 \n",
      "\n",
      "episode: 14/400, score: 11.0\n",
      "Average over last 100 episode: 15.47 \n",
      "\n",
      "episode: 15/400, score: 13.0\n",
      "Average over last 100 episode: 15.31 \n",
      "\n",
      "episode: 16/400, score: 11.0\n",
      "Average over last 100 episode: 15.06 \n",
      "\n",
      "episode: 17/400, score: 11.0\n",
      "Average over last 100 episode: 14.83 \n",
      "\n",
      "episode: 18/400, score: 11.0\n",
      "Average over last 100 episode: 14.63 \n",
      "\n",
      "episode: 19/400, score: 13.0\n",
      "Average over last 100 episode: 14.55 \n",
      "\n",
      "episode: 20/400, score: 13.0\n",
      "Average over last 100 episode: 14.48 \n",
      "\n",
      "episode: 21/400, score: 37.0\n",
      "Average over last 100 episode: 15.50 \n",
      "\n",
      "episode: 22/400, score: 63.0\n",
      "Average over last 100 episode: 17.57 \n",
      "\n",
      "episode: 23/400, score: 71.0\n",
      "Average over last 100 episode: 19.79 \n",
      "\n",
      "episode: 24/400, score: 47.0\n",
      "Average over last 100 episode: 20.88 \n",
      "\n",
      "episode: 25/400, score: 72.0\n",
      "Average over last 100 episode: 22.85 \n",
      "\n",
      "episode: 26/400, score: 86.0\n",
      "Average over last 100 episode: 25.19 \n",
      "\n",
      "episode: 27/400, score: 122.0\n",
      "Average over last 100 episode: 28.64 \n",
      "\n",
      "episode: 28/400, score: 200.0\n",
      "Average over last 100 episode: 34.55 \n",
      "\n",
      "episode: 29/400, score: 126.0\n",
      "Average over last 100 episode: 37.60 \n",
      "\n",
      "episode: 30/400, score: 200.0\n",
      "Average over last 100 episode: 42.84 \n",
      "\n",
      "episode: 31/400, score: 200.0\n",
      "Average over last 100 episode: 47.75 \n",
      "\n",
      "episode: 32/400, score: 200.0\n",
      "\n",
      " Task Completed! \n",
      "\n",
      "WARNING:tensorflow:From /Users/Vedant/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/Vedant/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Cartpole-model/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the output and plot the graph \n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "episodes = 400\n",
    "loss = train_dqn(episodes)\n",
    "plt.plot([i+1 for i in range(0, len(loss), 2)], loss[::2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
